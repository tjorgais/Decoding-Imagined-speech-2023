{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = {\"Long_words\": \"/home/tseringj/final_project/Long_Words\",\n",
    "               \"Short_Long_words\": \"/home/tseringj/final_project/Short_Long_words\",\n",
    "               \"Short_words\": \"/home/tseringj/final_project/Short_words\",\n",
    "               \"Vowels\": \"/home/tseringj/final_project/Vowels\"}\n",
    "\n",
    "words_dict = {\n",
    "    \"Long_words\": [\"cooperate\", \"independent\"],\n",
    "    \"Short_Long_words\": [\"cooperate\", \"in\"],\n",
    "    \"Short_words\": [\"out\", \"in\", \"up\"],\n",
    "    \"Vowels\": [\"a\", \"i\", \"u\"]\n",
    "}\n",
    "\n",
    "numeric_labels = {\n",
    "    \"Long_words\": {\"cooperate\": 0, \"independent\": 1},\n",
    "    \"Short_Long_words\": {\"cooperate\": 0, \"in\": 1},\n",
    "    \"Short_words\": {\"out\": 0, \"in\": 1, \"up\": 2},\n",
    "    \"Vowels\": {\"a\": 0, \"i\": 1, \"u\": 2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasub2 = sio.loadmat('Long_Words/sub_2b_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub3 = sio.loadmat('Long_Words/sub_3b_ch80_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub6 = sio.loadmat('Long_Words/sub_6_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub7 = sio.loadmat('Long_Words/sub_7_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub9 = sio.loadmat('Long_Words/sub_9c_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub11 = sio.loadmat('Long_Words/sub_11b_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mne.decoding import CSP\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matrix_to_load = \"eeg_data_wrt_task_rep_no_eog_256Hz_last_beep\"\n",
    "\n",
    "def load_EEG(type, subject_no):\n",
    "    path = folder_path[type]\n",
    "    words = words_dict[type]\n",
    "    for subject_file in os.scandir(path):\n",
    "        if not (subject_file.is_file() and subject_file.name.endswith('.mat') and\n",
    "                int(re.search(\"[0-9]+\", subject_file.name).group(0)) == subject_no):\n",
    "            continue\n",
    "        mat = sio.loadmat(subject_file.path)[matrix_to_load]\n",
    "        \n",
    "        temp = f\"{path}/temp_files3\"\n",
    "        if not os.path.exists(temp):\n",
    "            os.mkdir(temp)\n",
    "        temp = f\"{temp}/{subject_no}\"\n",
    "\n",
    "        if not os.path.exists(temp):\n",
    "            os.mkdir(temp)\n",
    "        X = []\n",
    "        Y = []\n",
    "        for index, eeg in np.ndenumerate(mat):\n",
    "            temp2 = f\"{temp}/{words[index[0]]}_{index[1] + 1}.npy\" #storing each trial\n",
    "            X.append(temp2)\n",
    "            Y.append(words[index[0]])\n",
    "            if not os.path.exists(temp2):\n",
    "                np.save(temp2, eeg)\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function for data augmentation\n",
    "\n",
    "# def train_augmentation(X,Y):\n",
    "#     final_X=np.empty((0,64,512))\n",
    "#     label=np.empty((0,1))\n",
    "    \n",
    "#     for i in range(len(X)):\n",
    "#         result=np.empty((4,64,512))\n",
    "#         with open(X[i], 'rb') as f:\n",
    "#             data = np.load(f)\n",
    "#             #channels_to_select = [i for i in range(64) if i not in [0, 9, 32, 63]]  # Channels to select (excluding 0, 9, 32, and 63)\n",
    "#             data=data[:,:1152]\n",
    "#             # Loop through the data with a stride of 64 samples\n",
    "#             k=0\n",
    "#             for j in range(0, 1125, 192):\n",
    "#                 if j+512 >= 1152:\n",
    "#                     break\n",
    "            \n",
    "\n",
    "#                 result[k,:,:] = data[:, j:j+512]\n",
    "#                 k+=1\n",
    "                \n",
    "#             final_X=np.vstack((final_X, result))\n",
    "#             if numeric_labels[type][Y[i]]==0:\n",
    "#               label=np.vstack((label, np.zeros((4,1))))\n",
    "#             else:\n",
    "#               label=np.vstack((label, np.ones((4,1))))\n",
    "            \n",
    "    \n",
    "    \n",
    "        \n",
    "#     return final_X,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for data augmentation\n",
    "\n",
    "def train_augmentation(X,Y):\n",
    "\n",
    "    total_samples=1152\n",
    "    stride=64\n",
    "    epoch_size=256\n",
    "    final_X=np.empty((0,64,epoch_size))\n",
    "    label=np.empty((0,1))\n",
    "    print(f'with total_sample: {total_samples}, epoch size: {epoch_size} and strides: {stride}')\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        #result=np.empty((4,64,512))\n",
    "        with open(X[i], 'rb') as f:\n",
    "            data = np.load(f)\n",
    "            # indices = np.arange(1, 17)\n",
    "            # indices = np.append(indices, np.arange(33, 49))\n",
    "            # indices = np.delete(indices, 9)\n",
    "            data=data[:,:total_samples]\n",
    "            # Loop through the data with a stride of 64 samples\n",
    "            \n",
    "            for j in range(0, total_samples, stride):\n",
    "                if j+epoch_size >= total_samples:\n",
    "                    break\n",
    "            \n",
    "\n",
    "                final_X = np.vstack((final_X,np.expand_dims(data[:, j:j+epoch_size],axis=0)))        \n",
    "                if numeric_labels[type][Y[i]]==0:\n",
    "                    label=np.vstack((label, np.zeros((1,1))))\n",
    "                else:\n",
    "                    label=np.vstack((label, np.ones((1,1))))\n",
    "            \n",
    "    \n",
    "    \n",
    "        \n",
    "    return final_X, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type=\"Long_words\"\n",
    "# subject_no=7\n",
    "# X,Y=load_EEG(type, subject_no)\n",
    "# data, label=train_augmentation(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    # precision = precision_score(y_test, y_pred)\n",
    "    # recall = recall_score(y_test, y_pred)\n",
    "    # f1 = f1_score(y_test, y_pred)\n",
    "    #print(f'accuracy: {accuracy}, precision: {precision}, recall: {recall}, f1 {f1}')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, X_test, y_train, y_test):\n",
    "\n",
    "  # Import other classifiers as needed\n",
    "\n",
    "  # Train classifiers with different n_components values\n",
    "  model_accuracies={}\n",
    "  svm_rbf=SVC(kernel='rbf')\n",
    "\n",
    "  svm_rbf.fit(X_train, y_train)\n",
    "  y_pred_rbf=svm_rbf.predict(X_test)\n",
    "  accuracy_rbf=calculate_performance(y_test, y_pred_rbf)\n",
    "  model_accuracies['svm_rbf']=accuracy_rbf\n",
    "  \n",
    "  svm_linear = SVC(kernel='linear')\n",
    "  svm_linear.fit(X_train, y_train)\n",
    "  y_pred_linear = svm_linear.predict(X_test)\n",
    "  print(\"pca linear performance: \")\n",
    "  accuracy_linear=calculate_performance(y_test, y_pred_linear)\n",
    "  model_accuracies['svm_linear']=accuracy_linear\n",
    "\n",
    "  \n",
    "  svm_poly = SVC(kernel='poly')\n",
    "  svm_poly.fit(X_train, y_train)\n",
    "  y_pred_poly = svm_poly.predict(X_test)\n",
    "  print(\"pca linear performance: \")\n",
    "  accuracy_poly=calculate_performance(y_test, y_pred_poly)\n",
    "  model_accuracies['svm_poly']=accuracy_poly\n",
    "\n",
    "\n",
    "  \n",
    "  rfc = RandomForestClassifier()\n",
    "  rfc.fit(X_train, y_train)\n",
    "  y_pred_rfc = rfc.predict(X_test)\n",
    "  print(\"Random Forest performance: \")\n",
    "  accuracy_rfc=calculate_performance(y_test, y_pred_rfc)\n",
    "  model_accuracies['rfc']=accuracy_rfc\n",
    " \n",
    "  k = 5  \n",
    "  knn = KNeighborsClassifier(n_neighbors=k)\n",
    "  knn.fit(X_train, y_train)\n",
    "  y_pred_knn = knn.predict(X_test)\n",
    "  print(\"KNN: \")\n",
    "  accuracy_knn=calculate_performance(y_test, y_pred_knn)\n",
    "  model_accuracies['knn']=accuracy_knn\n",
    "\n",
    "\n",
    "  mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=2000,activation='relu', solver='adam', random_state=42)\n",
    "  mlp.fit(X_train, y_train)\n",
    "  y_pred = mlp.predict(X_test)\n",
    "  y_pred_mlp = [round(value) for value in y_pred]\n",
    "  print('MLP performance: ')\n",
    "  accuracy_mlp=calculate_performance(y_test, y_pred_mlp)\n",
    "  model_accuracies['mlp']=accuracy_mlp\n",
    "\n",
    "\n",
    "  return model_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import LinAlgError\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_data(type,subject_no):\n",
    "    \n",
    "#     X,Y=load_EEG(type, subject_no)\n",
    "#     loo = LeaveOneOut()\n",
    "\n",
    "#     average_accuracies={}\n",
    "\n",
    "#     for i, (train_index, test_index) in enumerate(loo.split(X, Y)):\n",
    "#         train_X = X[train_index]\n",
    "#         train_y = Y[train_index]\n",
    "#         test_X = X[test_index]\n",
    "#         test_y = Y[test_index]\n",
    "#         X_train, y_train  = train_augmentation(train_X, train_y)\n",
    "#         X_test, y_test = train_augmentation(test_X, test_y)\n",
    "#         y_train=y_train.reshape((-1))\n",
    "#         y_test=y_test.reshape((-1))\n",
    "\n",
    "\n",
    "#         try:\n",
    "#             csp = CSP(n_components=4, reg=0.0003, log=False, norm_trace=False)\n",
    "#             csp.fit(X_train, y_train)\n",
    "#             X_train_csp = csp.transform(X_train)\n",
    "#             X_test_csp = csp.transform(X_test)\n",
    "#         except LinAlgError:\n",
    "#             print(\"LinAlgError occurred. Adjusting regularization parameter...\")\n",
    "#             try:\n",
    "#                 csp = CSP(n_components=4, reg=0.0002, log=False, norm_trace=False)\n",
    "#                 csp.fit(X_train, y_train)\n",
    "#                 X_train_csp = csp.transform(X_train)\n",
    "#                 X_test_csp = csp.transform(X_test)\n",
    "#             except LinAlgError:\n",
    "#                 print(\"LinAlgError occurred again. Consider further adjustments or preprocessing steps.\")\n",
    "                \n",
    "#                 try:\n",
    "#                     csp = CSP(n_components=4, reg=0.0001, log=False, norm_trace=False)\n",
    "#                     csp.fit(X_train, y_train)\n",
    "#                     X_train_csp = csp.transform(X_train)\n",
    "#                     X_test_csp = csp.transform(X_test)\n",
    "#                 except LinAlgError:\n",
    "#                     print(\"LinAlgError occurred again. Consider further adjustments or preprocessing steps.\")\n",
    "#         print(f'fold {i} performance: ')\n",
    "#         accuracies=train_model(X_train_csp, X_test_csp, y_train, y_test)\n",
    "#         for model_name, accuracy in accuracies.items():\n",
    "#             if model_name not in average_accuracies:\n",
    "#                 average_accuracies[model_name] = []\n",
    "#             average_accuracies[model_name].append(accuracy)\n",
    "#     for model_name, accuracies in average_accuracies.items():\n",
    "#         average_accuracy = np.mean(accuracies)\n",
    "#         std_deviation = np.std(accuracies)\n",
    "#         print(f\"{model_name} Average Accuracy: {average_accuracy}\")\n",
    "#         print(f\"{model_name} Standard Deviation: {std_deviation}\")\n",
    "\n",
    "\n",
    "#     return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(type,subject_no):\n",
    "    \n",
    "    X,Y=load_EEG(type, subject_no)\n",
    "    kfold=5\n",
    "    skf = StratifiedKFold(n_splits=kfold, random_state=42, shuffle=True)\n",
    "\n",
    "    average_accuracies={}\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, Y)):\n",
    "        train_X=X[train_index]\n",
    "        train_y=Y[train_index]\n",
    "        test_X=X[test_index]\n",
    "        test_y=Y[test_index]\n",
    "\n",
    "        X_train, y_train  = train_augmentation(train_X, train_y)\n",
    "        X_test, y_test = train_augmentation(test_X, test_y)\n",
    "        y_train=y_train.reshape((-1))\n",
    "        y_test=y_test.reshape((-1))\n",
    "\n",
    "\n",
    "        try:\n",
    "            csp = CSP(n_components=4, reg=0.0003, log=False, norm_trace=False)\n",
    "            csp.fit(X_train, y_train)\n",
    "            X_train_csp = csp.transform(X_train)\n",
    "            X_test_csp = csp.transform(X_test)\n",
    "        except LinAlgError:\n",
    "            print(\"LinAlgError occurred. Adjusting regularization parameter...\")\n",
    "            try:\n",
    "                csp = CSP(n_components=4, reg=0.0002, log=False, norm_trace=False)\n",
    "                csp.fit(X_train, y_train)\n",
    "                X_train_csp = csp.transform(X_train)\n",
    "                X_test_csp = csp.transform(X_test)\n",
    "            except LinAlgError:\n",
    "                print(\"LinAlgError occurred again. Consider further adjustments or preprocessing steps.\")\n",
    "                \n",
    "                try:\n",
    "                    csp = CSP(n_components=4, reg=0.0001, log=False, norm_trace=False)\n",
    "                    csp.fit(X_train, y_train)\n",
    "                    X_train_csp = csp.transform(X_train)\n",
    "                    X_test_csp = csp.transform(X_test)\n",
    "                except LinAlgError:\n",
    "                    print(\"LinAlgError occurred again. Consider further adjustments or preprocessing steps.\")\n",
    "        print(f'fold {i} performance: ')\n",
    "        accuracies=train_model(X_train_csp, X_test_csp, y_train, y_test)\n",
    "        for model_name, accuracy in accuracies.items():\n",
    "            if model_name not in average_accuracies:\n",
    "                average_accuracies[model_name] = []\n",
    "            average_accuracies[model_name].append(accuracy)\n",
    "    for model_name, accuracies in average_accuracies.items():\n",
    "        average_accuracy = np.mean(accuracies)\n",
    "        std_deviation = np.std(accuracies)\n",
    "        print(f\"{model_name} Average Accuracy: {average_accuracy}\")\n",
    "        print(f\"{model_name} Standard Deviation: {std_deviation}\")\n",
    "\n",
    "\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# type=\"Long_words\"\n",
    "# subject_no=6\n",
    "# get_data(type, subject_no)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm_rbf Average Accuracy: 0.52\n",
    "svm_rbf Standard Deviation: 0.030207614933986434\n",
    "svm_linear Average Accuracy: 0.5199999999999999\n",
    "svm_linear Standard Deviation: 0.034776069358108896\n",
    "svm_poly Average Accuracy: 0.50875\n",
    "svm_poly Standard Deviation: 0.004999999999999982\n",
    "rfc Average Accuracy: 0.53\n",
    "rfc Standard Deviation: 0.03999999999999999\n",
    "knn Average Accuracy: 0.51875\n",
    "knn Standard Deviation: 0.050466573095465865\n",
    "mlp Average Accuracy: 0.5625\n",
    "mlp Standard Deviation: 0.042938910093294175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now = datetime.now()\n",
    "# dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "# with open('csp_Attempts2.txt', 'w') as file:\n",
    "#     sys.stdout = file\n",
    "#     type=\"Long_words\"\n",
    "#     subject_no=[2,6,7,9,11]\n",
    "#     for i in range(len(subject_no)):\n",
    "#         print(f'subject no: {subject_no[i]}')\n",
    "#         get_data(type, subject_no[i])\n",
    "\n",
    "#     sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
