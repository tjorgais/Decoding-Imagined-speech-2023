{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = {\"Long_words\": \"/home/tseringj/final_project/Long_Words\",\n",
    "               \"Short_Long_words\": \"/home/tseringj/final_project/Short_Long_words\",\n",
    "               \"Short_words\": \"/home/tseringj/final_project/Short_words\",\n",
    "               \"Vowels\": \"/home/tseringj/final_project/Vowels\"}\n",
    "\n",
    "words_dict = {\n",
    "    \"Long_words\": [\"cooperate\", \"independent\"],\n",
    "    \"Short_Long_words\": [\"cooperate\", \"in\"],\n",
    "    \"Short_words\": [\"out\", \"in\", \"up\"],\n",
    "    \"Vowels\": [\"a\", \"i\", \"u\"]\n",
    "}\n",
    "\n",
    "numeric_labels = {\n",
    "    \"Long_words\": {\"cooperate\": 0, \"independent\": 1},\n",
    "    \"Short_Long_words\": {\"cooperate\": 0, \"in\": 1},\n",
    "    \"Short_words\": {\"out\": 0, \"in\": 1, \"up\": 2},\n",
    "    \"Vowels\": {\"a\": 0, \"i\": 1, \"u\": 2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasub2 = sio.loadmat('Long_Words/sub_2b_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub3 = sio.loadmat('Long_Words/sub_3b_ch80_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub6 = sio.loadmat('Long_Words/sub_6_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub7 = sio.loadmat('Long_Words/sub_7_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub9 = sio.loadmat('Long_Words/sub_9c_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub2 = sio.loadmat('Long_Words/sub_11b_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mne.decoding import CSP\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_fixer(data, n_epoch):\n",
    "    row,col=data[0][0].shape\n",
    "    X=np.empty((n_epoch, row, col))\n",
    "    for i in range(n_epoch):\n",
    "        X[i,:,:]=data[i][0]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Epoch_fixer(data):\n",
    "    row, col=data.shape\n",
    "    for i in range(row):\n",
    "        for j in range(col):\n",
    "            data[i][j]=data[i][j][:800]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data, n_comp):\n",
    "    \n",
    "    X = data.transpose()  # Transpose the data to have shape (100, 2)\n",
    "    y = np.zeros((2,100))\n",
    "    y[1,:]=1\n",
    "    y=y.transpose()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    X_train=X_train.reshape((160, -1))\n",
    "    X_test=X_test.reshape((40,-1))\n",
    "    y_train=y_train.reshape((160,-1)).reshape((-1))\n",
    "    y_test=y_test.reshape((40,-1)).reshape((-1))\n",
    "    X_train=data_fixer(X_train, X_train.shape[0])\n",
    "    X_test=data_fixer(X_test, X_test.shape[0])\n",
    "    \n",
    "    csp = CSP(n_components=n_comp, reg=0.001, log=False, norm_trace=False)\n",
    "    csp.fit(X_train, y_train)\n",
    "    X_train_csp = csp.transform(X_train)\n",
    "    X_test_csp = csp.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return X_train_csp, X_test_csp, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f'accuracy: {accuracy}, precision: {precision}, recall: {recall}, f1 {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, X_test, y_train, y_test):\n",
    "  scaler = StandardScaler()\n",
    "  train_pca = scaler.fit_transform(X_train)\n",
    "  test_pca = scaler.transform(X_test)\n",
    "  # train_data=X_train\n",
    "  # test_data=X_test\n",
    "\n",
    "  \n",
    "  y_train=y_train.astype(int)\n",
    "  y_test=y_test.astype(int)\n",
    "  print(sum(y_train), sum(y_test))\n",
    "  # Import other classifiers as needed\n",
    "\n",
    "  # Train classifiers with different n_components values\n",
    "  model=SVC(kernel='rbf')\n",
    "  model.fit(train_pca, y_train)\n",
    "  y_pred=model.predict(test_pca)\n",
    "  calculate_performance(y_test, y_pred)\n",
    "  \n",
    "  clf1 = SVC(kernel='linear')\n",
    "  clf1.fit(train_pca, y_train)\n",
    "  y_pred_pca = clf1.predict(test_pca)\n",
    "  print(\"pca linear performance: \")\n",
    "  calculate_performance(y_test, y_pred_pca)\n",
    "\n",
    "\n",
    "  \n",
    "  clf2 = RandomForestClassifier()\n",
    "  clf2.fit(train_pca, y_train)\n",
    "  y_pred_rfc = clf2.predict(test_pca)\n",
    "  print(\"Random Forest performance: \")\n",
    "  calculate_performance(y_test, y_pred_rfc)\n",
    "\n",
    "  model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500,activation='relu', solver='adam', random_state=42)\n",
    "  model.fit(train_pca, y_train)\n",
    "  y_pred = model.predict(test_pca)\n",
    "  y_pred_mlp = [round(value) for value in y_pred]\n",
    "  print('MLP performance: ')\n",
    "  calculate_performance(y_test, y_pred_mlp)\n",
    "\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasub2=Epoch_fixer(datasub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tseringj/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/tseringj/.local/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "with open('csp_Attempts.txt', 'a') as file:\n",
    "    sys.stdout = file\n",
    "    n_components=[2,4,6,8,10]\n",
    "    for i in range(len(n_components)):\n",
    "        print(\"time: \", dt_string)\n",
    "        print(f'n_components: {n_components[i]}')\n",
    "        X_train, X_test, y_train, y_test=get_data(datasub2,n_components[i])\n",
    "        train_model(X_train, X_test, y_train, y_test)\n",
    "    sys.stdout = sys.__stdout__\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
