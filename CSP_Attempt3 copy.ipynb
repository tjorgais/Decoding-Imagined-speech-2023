{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = {\"Long_words\": \"/home/tseringj/final_project/Long_Words\",\n",
    "               \"Short_Long_words\": \"/home/tseringj/final_project/Short_Long_words\",\n",
    "               \"Short_words\": \"/home/tseringj/final_project/Short_words\",\n",
    "               \"Vowels\": \"/home/tseringj/final_project/Vowels\"}\n",
    "\n",
    "words_dict = {\n",
    "    \"Long_words\": [\"cooperate\", \"independent\"],\n",
    "    \"Short_Long_words\": [\"cooperate\", \"in\"],\n",
    "    \"Short_words\": [\"out\", \"in\", \"up\"],\n",
    "    \"Vowels\": [\"a\", \"i\", \"u\"]\n",
    "}\n",
    "\n",
    "numeric_labels = {\n",
    "    \"Long_words\": {\"cooperate\": 0, \"independent\": 1},\n",
    "    \"Short_Long_words\": {\"cooperate\": 0, \"in\": 1},\n",
    "    \"Short_words\": {\"out\": 0, \"in\": 1, \"up\": 2},\n",
    "    \"Vowels\": {\"a\": 0, \"i\": 1, \"u\": 2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasub2 = sio.loadmat('Long_Words/sub_2b_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub3 = sio.loadmat('Long_Words/sub_3b_ch80_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub6 = sio.loadmat('Long_Words/sub_6_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub7 = sio.loadmat('Long_Words/sub_7_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub9 = sio.loadmat('Long_Words/sub_9c_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub11 = sio.loadmat('Long_Words/sub_11b_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mne.decoding import CSP\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matrix_to_load = \"eeg_data_wrt_task_rep_no_eog_256Hz_last_beep\"\n",
    "\n",
    "def load_EEG(type, subject_no):\n",
    "    path = folder_path[type]\n",
    "    words = words_dict[type]\n",
    "    for subject_file in os.scandir(path):\n",
    "        if not (subject_file.is_file() and subject_file.name.endswith('.mat') and\n",
    "                int(re.search(\"[0-9]+\", subject_file.name).group(0)) == subject_no):\n",
    "            continue\n",
    "        mat = sio.loadmat(subject_file.path)[matrix_to_load]\n",
    "        \n",
    "        temp = f\"{path}/temp_files3\"\n",
    "        if not os.path.exists(temp):\n",
    "            os.mkdir(temp)\n",
    "        temp = f\"{temp}/{subject_no}\"\n",
    "\n",
    "        if not os.path.exists(temp):\n",
    "            os.mkdir(temp)\n",
    "        X = []\n",
    "        Y = []\n",
    "        for index, eeg in np.ndenumerate(mat):\n",
    "            temp2 = f\"{temp}/{words[index[0]]}_{index[1] + 1}.npy\" #storing each trial\n",
    "            X.append(temp2)\n",
    "            Y.append(words[index[0]])\n",
    "            if not os.path.exists(temp2):\n",
    "                np.save(temp2, eeg)\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function for data augmentation\n",
    "\n",
    "# def train_augmentation(X,Y):\n",
    "\n",
    "#     final_X=np.empty((0,64,1280))\n",
    "#     label=np.empty((0,1))\n",
    "\n",
    "    \n",
    "#     for i in range(len(X)):\n",
    "#         #result=np.empty((4,64,512))\n",
    "#         with open(X[i], 'rb') as f:\n",
    "#             data = np.load(f)\n",
    "#             # indices = np.arange(1, 17)\n",
    "#             # indices = np.append(indices, np.arange(33, 49))\n",
    "#             # indices = np.delete(indices, 9)\n",
    "\n",
    "#             # Loop through the data with a stride of 64 samples\n",
    "\n",
    "            \n",
    "\n",
    "#             final_X = np.vstack((final_X,np.expand_dims(data,axis=0)))        \n",
    "#             if numeric_labels[type][Y[i]]==0:\n",
    "#                 label=np.vstack((label, np.zeros((1,1))))\n",
    "#             else:\n",
    "#                 label=np.vstack((label, np.ones((1,1))))\n",
    "            \n",
    "    \n",
    "    \n",
    "        \n",
    "#     return final_X, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for data augmentation\n",
    "\n",
    "def train_augmentation(X,Y):\n",
    "\n",
    "    total_samples=1152\n",
    "    stride=250\n",
    "    epoch_size=512\n",
    "    final_X=np.empty((0,60,epoch_size))\n",
    "    label=np.empty((0,1))\n",
    "    print(f'with total_sample: {total_samples}, epoch size: {epoch_size} and strides: {stride}')\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        #result=np.empty((4,64,512))\n",
    "        with open(X[i], 'rb') as f:\n",
    "            data = np.load(f)\n",
    "            indices = np.arange(1, 32)\n",
    "            indices = np.append(indices, np.arange(33, 63))\n",
    "            indices = np.delete(indices, 8)\n",
    "            data=data[indices,:total_samples]\n",
    "            # Loop through the data with a stride of 64 samples\n",
    "            \n",
    "            for j in range(0, total_samples, stride):\n",
    "                if j+epoch_size >= total_samples:\n",
    "                    break\n",
    "            \n",
    "\n",
    "                final_X = np.vstack((final_X,np.expand_dims(data[:, j:j+epoch_size],axis=0)))        \n",
    "                if numeric_labels[type][Y[i]]==0:\n",
    "                    label=np.vstack((label, np.zeros((1,1))))\n",
    "                else:\n",
    "                    label=np.vstack((label, np.ones((1,1))))\n",
    "            \n",
    "    \n",
    "    \n",
    "        \n",
    "    return final_X, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    # precision = precision_score(y_test, y_pred)\n",
    "    # recall = recall_score(y_test, y_pred)\n",
    "    # f1 = f1_score(y_test, y_pred)\n",
    "    #print(f'accuracy: {accuracy}, precision: {precision}, recall: {recall}, f1 {f1}')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, X_test, y_train, y_test):\n",
    "\n",
    "  # Import other classifiers as needed\n",
    "\n",
    "  # Train classifiers with different n_components values\n",
    "  model_accuracies={}\n",
    "  svm_rbf=SVC(kernel='rbf')\n",
    "\n",
    "  svm_rbf.fit(X_train, y_train)\n",
    "  y_pred_rbf=svm_rbf.predict(X_test)\n",
    "  accuracy_rbf=calculate_performance(y_test, y_pred_rbf)\n",
    "  model_accuracies['svm_rbf']=accuracy_rbf\n",
    "  \n",
    "  svm_linear = SVC(kernel='linear')\n",
    "  svm_linear.fit(X_train, y_train)\n",
    "  y_pred_linear = svm_linear.predict(X_test)\n",
    "  print(\"pca linear performance: \")\n",
    "  accuracy_linear=calculate_performance(y_test, y_pred_linear)\n",
    "  model_accuracies['svm_linear']=accuracy_linear\n",
    "\n",
    "  \n",
    "  svm_poly = SVC(kernel='poly')\n",
    "  svm_poly.fit(X_train, y_train)\n",
    "  y_pred_poly = svm_poly.predict(X_test)\n",
    "  print(\"pca linear performance: \")\n",
    "  accuracy_poly=calculate_performance(y_test, y_pred_poly)\n",
    "  model_accuracies['svm_poly']=accuracy_poly\n",
    "\n",
    "\n",
    "  \n",
    "  rfc = RandomForestClassifier()\n",
    "  rfc.fit(X_train, y_train)\n",
    "  y_pred_rfc = rfc.predict(X_test)\n",
    "  print(\"Random Forest performance: \")\n",
    "  accuracy_rfc=calculate_performance(y_test, y_pred_rfc)\n",
    "  model_accuracies['rfc']=accuracy_rfc\n",
    " \n",
    "  k = 5  \n",
    "  knn = KNeighborsClassifier(n_neighbors=k)\n",
    "  knn.fit(X_train, y_train)\n",
    "  y_pred_knn = knn.predict(X_test)\n",
    "  print(\"KNN: \")\n",
    "  accuracy_knn=calculate_performance(y_test, y_pred_knn)\n",
    "  model_accuracies['knn']=accuracy_knn\n",
    "\n",
    "\n",
    "  mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=2000,activation='relu', solver='adam', random_state=42)\n",
    "  mlp.fit(X_train, y_train)\n",
    "  y_pred = mlp.predict(X_test)\n",
    "  y_pred_mlp = [round(value) for value in y_pred]\n",
    "  print('MLP performance: ')\n",
    "  accuracy_mlp=calculate_performance(y_test, y_pred_mlp)\n",
    "  model_accuracies['mlp']=accuracy_mlp\n",
    "\n",
    "\n",
    "  return model_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import LinAlgError\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def get_data(type,subject_no):\n",
    "    \n",
    "#     X,Y=load_EEG(type, subject_no)\n",
    "#     loo = LeaveOneOut()\n",
    "\n",
    "#     average_accuracies={}\n",
    "\n",
    "#     for i, (train_index, test_index) in enumerate(loo.split(X, Y)):\n",
    "#         train_X = X[train_index]\n",
    "#         train_y = Y[train_index]\n",
    "#         test_X = X[test_index]\n",
    "#         test_y = Y[test_index]\n",
    "#         X_train, y_train  = train_augmentation(train_X, train_y)\n",
    "#         X_test, y_test = train_augmentation(test_X, test_y)\n",
    "#         y_train=y_train.reshape((-1))\n",
    "#         y_test=y_test.reshape((-1))\n",
    "\n",
    "\n",
    "#         try:\n",
    "#             csp = CSP(n_components=4, reg=0.0003, log=False, norm_trace=False)\n",
    "#             csp.fit(X_train, y_train)\n",
    "#             X_train_csp = csp.transform(X_train)\n",
    "#             X_test_csp = csp.transform(X_test)\n",
    "#         except LinAlgError:\n",
    "#             print(\"LinAlgError occurred. Adjusting regularization parameter...\")\n",
    "#             try:\n",
    "#                 csp = CSP(n_components=4, reg=0.0002, log=False, norm_trace=False)\n",
    "#                 csp.fit(X_train, y_train)\n",
    "#                 X_train_csp = csp.transform(X_train)\n",
    "#                 X_test_csp = csp.transform(X_test)\n",
    "#             except LinAlgError:\n",
    "#                 print(\"LinAlgError occurred again. Consider further adjustments or preprocessing steps.\")\n",
    "                \n",
    "#                 try:\n",
    "#                     csp = CSP(n_components=4, reg=0.0001, log=False, norm_trace=False)\n",
    "#                     csp.fit(X_train, y_train)\n",
    "#                     X_train_csp = csp.transform(X_train)\n",
    "#                     X_test_csp = csp.transform(X_test)\n",
    "#                 except LinAlgError:\n",
    "#                     print(\"LinAlgError occurred again. Consider further adjustments or preprocessing steps.\")\n",
    "#         print(f'fold {i} performance: ')\n",
    "#         accuracies=train_model(X_train_csp, X_test_csp, y_train, y_test)\n",
    "#         for model_name, accuracy in accuracies.items():\n",
    "#             if model_name not in average_accuracies:\n",
    "#                 average_accuracies[model_name] = []\n",
    "#             average_accuracies[model_name].append(accuracy)\n",
    "#     for model_name, accuracies in average_accuracies.items():\n",
    "#         average_accuracy = np.mean(accuracies)\n",
    "#         std_deviation = np.std(accuracies)\n",
    "#         print(f\"{model_name} Average Accuracy: {average_accuracy}\")\n",
    "#         print(f\"{model_name} Standard Deviation: {std_deviation}\")\n",
    "\n",
    "\n",
    "#     return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyriemann.classification import MDM, TSclassifier, FgMDM\n",
    "from pyriemann.estimation import Covariances\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pyriemann.channelselection import ElectrodeSelection\n",
    "from pyriemann.channelselection import FlatChannelRemover\n",
    "\n",
    "from pyriemann.tangentspace import FGDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_data(type,subject_no):\n",
    "    \n",
    "#     X,Y=load_EEG(type, subject_no)\n",
    "\n",
    "\n",
    "#     X_train, y_train  = train_augmentation(X, Y)\n",
    "\n",
    "#     y_train=y_train.reshape((-1))\n",
    "\n",
    "#     cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#     cov_data_train = Covariances(estimator='lwf').transform(X_train)\n",
    "    \n",
    "#     mdm = MDM(metric=dict(mean='riemann', distance='riemann'))\n",
    "    \n",
    "\n",
    "#     scores_mdm = cross_val_score(mdm, cov_data_train, y_train, cv=cv, n_jobs=1)\n",
    "#     print(f\"MDM Classification Average Accuracy: {np.mean(scores_mdm)}, MDM Classification Average Std: {np.std(scores_mdm)}\")\n",
    "\n",
    "#     tsc = TSclassifier()\n",
    "#     # Use scikit-learn Pipeline with cross_val_score function\n",
    "#     scores_tsc = cross_val_score(tsc, cov_data_train, y_train, cv=cv, n_jobs=1)\n",
    "#     print(f\"TSC Classification Average Accuracy: {np.mean(scores_tsc)}, TSC Classification Average Std: {np.std(scores_tsc)}\")\n",
    "\n",
    "#     lr = LogisticRegression()\n",
    "#     csp = CSP(n_components=4, reg='ledoit_wolf', log=True)\n",
    "#     csp = Pipeline([('CSP', csp), ('LogisticRegression', lr)])\n",
    "#     scores_csp = cross_val_score(csp, X_train, y_train, cv=cv, n_jobs=1)\n",
    "#     print(f\" Classification Average Accuracy: {np.mean(scores_csp)}, MDM Classification Average Std: {np.std(scores_csp)}\")\n",
    "\n",
    "#     return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type=\"Long_words\"\n",
    "# subject_no=9\n",
    "# get_data(type, subject_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(type,subject_no):\n",
    "    \n",
    "    X,Y=load_EEG(type, subject_no)\n",
    "    kfold=5\n",
    "    skf = StratifiedKFold(n_splits=kfold, random_state=42, shuffle=True)\n",
    "\n",
    "    mdm_test_scores=[]\n",
    "    tsc_test_scores=[]\n",
    "    fgmdm_test_scores=[]\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, Y)):\n",
    "      train_X=X[train_index]\n",
    "      train_y=Y[train_index]\n",
    "      test_X=X[test_index]\n",
    "      test_y=Y[test_index]\n",
    "\n",
    "      X_train, y_train  = train_augmentation(train_X, train_y)\n",
    "      X_test, y_test = train_augmentation(test_X, test_y)\n",
    "      y_train=y_train.reshape((-1))\n",
    "      y_test=y_test.reshape((-1))\n",
    "      #cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "      channel_remover = FlatChannelRemover()\n",
    "\n",
    "      X_train = channel_remover.fit_transform(X_train, y_train)\n",
    "      X_test =channel_remover.transform(X_test)\n",
    "      print(X_train.shape)\n",
    "      \n",
    "      cov_data_train = Covariances(estimator='lwf').transform(X_train)\n",
    "      cov_data_test=Covariances(estimator='lwf').transform(X_test)\n",
    "      ecs=ElectrodeSelection(nelec=20, metric='riemann', n_jobs=1)\n",
    "      ecs.fit(cov_data_train, y_train)\n",
    "      cov_data_train=ecs.transform(cov_data_train)\n",
    "      cov_data_test=ecs.transform(cov_data_test)\n",
    "\n",
    "      # fgda=FGDA(metric='riemann', tsupdate=False)\n",
    "      # cov_data_train=fgda.fit_transform(cov_data_train, y_train)\n",
    "      # cov_data_test=fgda.transform(cov_data_test)\n",
    "      \n",
    "      mdm = MDM(metric=dict(mean='riemann', distance='riemann'))\n",
    "      mdm.fit(cov_data_train, y_train)\n",
    "      #scores_mdm = cross_val_score(mdm, cov_data_train, y_train, cv=cv, n_jobs=1)\n",
    "      predict_mdm = mdm.predict(cov_data_test)\n",
    "      mdm_test_scores.append(accuracy_score(y_test, predict_mdm))\n",
    "\n",
    "\n",
    "      #print(f\"MDM Classification Average Accuracy: {np.mean(scores_mdm)}, MDM Classification Average Std: {np.std(scores_mdm)}\")\n",
    "      svm_rbf=SVC(kernel='rbf')\n",
    "      tsc = TSclassifier(tsupdate=True, clf=svm_rbf)\n",
    "      tsc.fit(cov_data_train, y_train)\n",
    "      #scores_tsc = cross_val_score(tsc, cov_data_train, y_train, cv=cv, n_jobs=1)\n",
    "      predict_tsc = tsc.predict(cov_data_test)\n",
    "      tsc_test_scores.append(accuracy_score(y_test, predict_tsc))\n",
    "\n",
    "      fgmdm = FgMDM(metric=dict(mean='riemann', distance='riemann', map='riemann'), tsupdate=True)\n",
    "      fgmdm.fit(cov_data_train, y_train)\n",
    "      #scores_mdm = cross_val_score(mdm, cov_data_train, y_train, cv=cv, n_jobs=1)\n",
    "      predict_fgmdm = fgmdm.predict(cov_data_test)\n",
    "      fgmdm_test_scores.append(accuracy_score(y_test, predict_fgmdm))\n",
    "\n",
    "      \n",
    "\n",
    "      #print(f\"MDM Classification Average Accuracy: {np.mean(scores_tsc)}, MDM Classification Average Std: {np.std(scores_tsc)}\")\n",
    "\n",
    "      # lr = LogisticRegression()\n",
    "      # csp = CSP(n_components=4, reg='ledoit_wolf', log=True)\n",
    "      # csp = Pipeline([('CSP', csp), ('LogisticRegression', lr)])\n",
    "      # scores_csp = cross_val_score(csp, X_train, y_train, cv=cv, n_jobs=1)\n",
    "      # predict_csp = csp.predict(cov_data_test)\n",
    "      # csp_test_scores.append(accuracy_score(y_test, predict_csp))\n",
    "      #print(f\" Classification Average Accuracy: {np.mean(scores_csp)}, MDM Classification Average Std: {np.std(scores_csp)}\")\n",
    "    print(f\"MDM Classification Average Test Accuracy: {np.mean(mdm_test_scores)}, MDM Classification Average Test Std: {np.std(mdm_test_scores)}\")\n",
    "    print(f\"TSC Classification Average Test Accuracy: {np.mean(tsc_test_scores)}, TSC Classification Average Test Std: {np.std(tsc_test_scores)}\")\n",
    "    print(f\"FgMDM Classification Average Test Accuracy: {np.mean(fgmdm_test_scores)}, FgMDM Classification Average Test Std: {np.std(fgmdm_test_scores)}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type=\"Long_words\"\n",
    "# subject_no=7\n",
    "# get_data(type, subject_no)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm_rbf Average Accuracy: 0.52\n",
    "svm_rbf Standard Deviation: 0.030207614933986434\n",
    "svm_linear Average Accuracy: 0.5199999999999999\n",
    "svm_linear Standard Deviation: 0.034776069358108896\n",
    "svm_poly Average Accuracy: 0.50875\n",
    "svm_poly Standard Deviation: 0.004999999999999982\n",
    "rfc Average Accuracy: 0.53\n",
    "rfc Standard Deviation: 0.03999999999999999\n",
    "knn Average Accuracy: 0.51875\n",
    "knn Standard Deviation: 0.050466573095465865\n",
    "mlp Average Accuracy: 0.5625\n",
    "mlp Standard Deviation: 0.042938910093294175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# now = datetime.now()\n",
    "# dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "# with open('csp_Attempts3_copy.txt', 'a') as file:\n",
    "#     sys.stdout = file\n",
    "#     print('*******************************************************************************')\n",
    "#     type=\"Long_words\"\n",
    "#     subject_no=[2,6,7,9,11]\n",
    "#     for i in range(len(subject_no)):\n",
    "#         print(f'subject no: {subject_no[i]}')\n",
    "#         get_data(type, subject_no[i])\n",
    "\n",
    "#     sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "with open('csp_Attempts3_copy.txt', 'a') as file:\n",
    "    sys.stdout = file\n",
    "    print('*******************************************************************************')\n",
    "    type=\"Short_Long_words\"\n",
    "    subject_no=[1,5,8,9,10,14]\n",
    "    for i in range(len(subject_no)):\n",
    "        print(f'subject no: {subject_no[i]}')\n",
    "        get_data(type, subject_no[i])\n",
    "\n",
    "    sys.stdout = sys.__stdout__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
