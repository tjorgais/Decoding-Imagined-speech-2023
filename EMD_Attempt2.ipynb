{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dt5km8cjt8ei"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tseringj/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.io as sio\n",
        "from scipy import signal\n",
        "import numpy as np\n",
        "from PyEMD import EMD\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import kurtosis, skew\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xEU15xV1t8em"
      },
      "outputs": [],
      "source": [
        "folder_path = {\"Long_words\": \"/home/tseringj/final_project/Long_Words\",\n",
        "               \"Short_Long_words\": \"/home/tseringj/final_project/Short_Long_words\",\n",
        "               \"Short_words\": \"/home/tseringj/final_project/Short_words\",\n",
        "               \"Vowels\": \"/home/tseringj/final_project/Vowels\"}\n",
        "\n",
        "words_dict = {\n",
        "    \"Long_words\": [\"cooperate\", \"independent\"],\n",
        "    \"Short_Long_words\": [\"cooperate\", \"in\"],\n",
        "    \"Short_words\": [\"out\", \"in\", \"up\"],\n",
        "    \"Vowels\": [\"a\", \"i\", \"u\"]\n",
        "}\n",
        "\n",
        "numeric_labels = {\n",
        "    \"Long_words\": {\"cooperate\": 0, \"independent\": 1},\n",
        "    \"Short_Long_words\": {\"cooperate\": 0, \"in\": 1},\n",
        "    \"Short_words\": {\"out\": 0, \"in\": 1, \"up\": 2},\n",
        "    \"Vowels\": {\"a\": 0, \"i\": 1, \"u\": 2}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NgXwegMLt8en"
      },
      "outputs": [],
      "source": [
        "# datasub2 = sio.loadmat('Long_Words/sub_2b_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
        "#datasub3 = sio.loadmat('Long_Words/sub_3b_ch80_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
        "# datasub6 = sio.loadmat('Long_Words/sub_6_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
        "# datasub7 = sio.loadmat('Long_Words/sub_7_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
        "# datasub9 = sio.loadmat('Long_Words/sub_9c_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
        "# datasub11 = sio.loadmat('Long_Words/sub_11b_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "k9K0AmA8t8eo"
      },
      "outputs": [],
      "source": [
        "\n",
        "matrix_to_load = \"eeg_data_wrt_task_rep_no_eog_256Hz_last_beep\"\n",
        "\n",
        "def load_EEG(type, subject_no):\n",
        "    path = folder_path[type]\n",
        "    words = words_dict[type]\n",
        "    for subject_file in os.scandir(path):\n",
        "        if not (subject_file.is_file() and subject_file.name.endswith('.mat') and\n",
        "                int(re.search(\"[0-9]+\", subject_file.name).group(0)) == subject_no):\n",
        "            continue\n",
        "        mat = sio.loadmat(subject_file.path)[matrix_to_load]\n",
        "        \n",
        "        temp = f\"{path}/temp_files3\"\n",
        "        if not os.path.exists(temp):\n",
        "            os.mkdir(temp)\n",
        "        temp = f\"{temp}/{subject_no}\"\n",
        "\n",
        "        if not os.path.exists(temp):\n",
        "            os.mkdir(temp)\n",
        "        X = []\n",
        "        Y = []\n",
        "        for index, eeg in np.ndenumerate(mat):\n",
        "            temp2 = f\"{temp}/{words[index[0]]}_{index[1] + 1}.npy\" #storing each trial\n",
        "            X.append(temp2)\n",
        "            Y.append(words[index[0]])\n",
        "            if not os.path.exists(temp2):\n",
        "                np.save(temp2, eeg)\n",
        "    return np.array(X), np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PRH6XdDQt8ep"
      },
      "outputs": [],
      "source": [
        "# # function for data augmentation\n",
        "\n",
        "# def train_augmentation(X,Y):\n",
        "#     final_X=np.empty((0,64,512))\n",
        "#     label=np.empty((0,1))\n",
        "    \n",
        "#     for i in range(len(X)):\n",
        "#         result=np.empty((4,64,512))\n",
        "#         with open(X[i], 'rb') as f:\n",
        "#             data = np.load(f)\n",
        "#             #channels_to_select = [i for i in range(64) if i not in [0, 9, 32, 63]]  # Channels to select (excluding 0, 9, 32, and 63)\n",
        "#             data=data[:,:1152]\n",
        "#             # Loop through the data with a stride of 64 samples\n",
        "#             k=0\n",
        "#             for j in range(0, 1125, 192):\n",
        "#                 if j+512 >= 1152:\n",
        "#                     break\n",
        "            \n",
        "\n",
        "#                 result[k,:,:] = data[:, j:j+512]\n",
        "#                 k+=1\n",
        "                \n",
        "#             final_X=np.vstack((final_X, result))\n",
        "#             if numeric_labels[type][Y[i]]==0:\n",
        "#               label=np.vstack((label, np.zeros((4,1))))\n",
        "#             else:\n",
        "#               label=np.vstack((label, np.ones((4,1))))\n",
        "            \n",
        "    \n",
        "    \n",
        "        \n",
        "#     return final_X,label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Hd8TQdnjt8er"
      },
      "outputs": [],
      "source": [
        "def Calculate_PSD(signal):\n",
        "\n",
        "    frequencies, psd = signal.welch(signal, fs=256)  # Adjust the sampling frequency (fs) if needed\n",
        "\n",
        "    # Plot the PSD\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(frequencies, psd)\n",
        "    plt.xlabel('Frequency (Hz)')\n",
        "    plt.ylabel('Power Spectral Density')\n",
        "    plt.title('Power Spectral Density of IMF')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SOM3YoUNb7QK"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2ewnl9YfXfug"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def compute_time_domain_features(eeg_data):\n",
        "    \n",
        "    time_features = {}\n",
        "\n",
        "    # Mean\n",
        "    time_features['mean'] = np.mean(eeg_data)\n",
        "\n",
        "    # # Standard deviation\n",
        "    time_features['std'] = np.std(eeg_data)\n",
        "\n",
        "    # # Kurtosis\n",
        "    #time_features['kurtosis'] = kurtosis(eeg_data)\n",
        "\n",
        "    # # Energy\n",
        "    #time_features['Energy'] = np.sum(np.square(eeg_data))\n",
        "\n",
        "    # # RMS (Root Mean Square)\n",
        "    time_features['RMS'] = np.sqrt(np.mean(np.square(eeg_data)))\n",
        "\n",
        "    # # Zero-crossing rate\n",
        "    # zero_crossings = np.where(np.diff(np.sign(eeg_data)))[0]\n",
        "    # zero_crossing_rate = len(zero_crossings) / (len(eeg_data) - 1)\n",
        "    # time_features['Zero-crossing rate'] = zero_crossing_rate\n",
        "\n",
        "    # # Hjorth parameters\n",
        "    # # Hjorth parameters\n",
        "    #time_features['hjorth_activity'] = np.sqrt(np.sum(np.square(eeg_data)) / time_features['std']**2)\n",
        "    #time_features['hjorth_mobility'] = time_features['mean'] / time_features['std']\n",
        "    #time_features['hjorth_complexity'] = kurtosis(eeg_data) / (time_features['std']**4)\n",
        "\n",
        "    # Skewness\n",
        "    time_features['Skewness'] = skew(eeg_data)\n",
        "\n",
        "    # Median\n",
        "    time_features['Median'] = np.median(eeg_data)\n",
        "\n",
        "\n",
        "    # # Range\n",
        "    #time_features['Range'] = np.ptp(eeg_data)\n",
        "\n",
        "    # # Inter-quartile range\n",
        "    # time_features['Inter-quartile range'] = np.percentile(eeg_data, 75) - np.percentile(eeg_data, 25)\n",
        "\n",
        "    # # Variance\n",
        "    # time_features['Variance'] = np.var(eeg_data)\n",
        "\n",
        "    # # Autocorrelation\n",
        "    # autocorr = np.correlate(eeg_data, eeg_data, mode='full')\n",
        "    # time_features['Autocorrelation'] = autocorr[len(autocorr)//2:]\n",
        "\n",
        "\n",
        "    # Compute power spectral density using Welch's method\n",
        "    # frequencies, psd = signal.welch(eeg_data, fs=256)\n",
        "\n",
        "    # Calculate total power as a spectral feature\n",
        "    # total_power = np.sum(psd)\n",
        "    # time_features['total_power'] = total_power\n",
        "\n",
        "    # Calculate spectral entropy as a spectral feature\n",
        "    # normalized_psd = psd / np.sum(psd)  # Normalize PSD values\n",
        "    # spectral_entropy = entropy(normalized_psd, base=2)\n",
        "    # time_features['spectral_entropy'] = spectral_entropy\n",
        "\n",
        "    \n",
        "\n",
        "    # Assuming you have the IMF signal stored in a variable called 'imf_signal'\n",
        "\n",
        "\n",
        "\n",
        "    return list(time_features.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bZ-J6xs8t8es"
      },
      "outputs": [],
      "source": [
        "def feature_extraction(data):\n",
        "    row, col=data.shape\n",
        "    feature=[]\n",
        "    for i in range(row):\n",
        "        emd = EMD()\n",
        "        IMFs = emd(data[i,:], max_imf=5)\n",
        "        \n",
        "        feature_imfs=[]\n",
        "\n",
        "            \n",
        "        feature_imfs=compute_time_domain_features(IMFs[2,:])\n",
        "        feature.extend(feature_imfs)\n",
        "\n",
        "\n",
        "    return feature\n",
        "        \n",
        "\n",
        "\n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mwjYREMet8et"
      },
      "outputs": [],
      "source": [
        "# function for data augmentation\n",
        "\n",
        "def train_augmentation(X,Y):\n",
        "\n",
        "    total_samples=1152\n",
        "    stride=192\n",
        "    epoch_size=512\n",
        "    # final_X=np.empty((0,64,epoch_size))\n",
        "    # label=np.empty((0,1))\n",
        "    print(f'with total_sample: {total_samples}, epoch size: {epoch_size} and strides: {stride}')\n",
        "    final_data=np.empty((0,155))\n",
        "    label=np.empty((0,1))\n",
        "    \n",
        "    for i in range(len(X)):\n",
        "        #result=np.empty((4,64,512))\n",
        "        with open(X[i], 'rb') as f:\n",
        "            data = np.load(f)\n",
        "\n",
        "            indices = np.arange(1, 17)\n",
        "            indices = np.append(indices, np.arange(33, 49))\n",
        "            indices = np.delete(indices, 9)\n",
        "\n",
        "            # indices = np.arange(17, 32)\n",
        "            # indices = np.append(indices, np.arange(49, 64))\n",
        "            \n",
        "\n",
        "\n",
        "            data = data[indices, :total_samples]\n",
        "\n",
        "            # feature=feature_extraction(data)\n",
        "            # feature=np.array(feature).reshape((1,-1))\n",
        "            \n",
        "            # if numeric_labels[type][Y[i]]==0:\n",
        "            #     label=np.vstack((label, np.zeros((1,1))))\n",
        "            # else:\n",
        "            #     label=np.vstack((label, np.ones((1,1))))\n",
        "            # final_data=np.vstack((final_data, feature))\n",
        "\n",
        "            \n",
        "\n",
        "\n",
        "            \n",
        "            for j in range(0, total_samples, stride):\n",
        "                if j+epoch_size >= total_samples:\n",
        "                    break\n",
        "            \n",
        "\n",
        "                feature=feature_extraction(data)\n",
        "                feature=np.array(feature).reshape((1,-1))\n",
        "                # print(feature.shape)\n",
        "                if numeric_labels[type][Y[i]]==0:\n",
        "                    label=np.vstack((label, np.zeros((1,1))))\n",
        "                else:\n",
        "                    label=np.vstack((label, np.ones((1,1))))\n",
        "                final_data=np.vstack((final_data, feature))       \n",
        "\n",
        "        \n",
        "            \n",
        "    \n",
        "    \n",
        "        \n",
        "    return final_data, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "awsPTZDqt8et"
      },
      "outputs": [],
      "source": [
        "# type=\"Long_words\"\n",
        "# subject_no=7\n",
        "# X,Y=load_EEG(type, subject_no)\n",
        "# data, label=train_augmentation(X,Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BLtTg5Z5VpaV"
      },
      "outputs": [],
      "source": [
        "# data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "n24FakzXVpaX"
      },
      "outputs": [],
      "source": [
        "def calculate_performance(y_test, y_pred):\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    print(f'accuracy: {accuracy}, precision: {precision}, recall: {recall}, f1 {f1}')\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vKtPLVIVVpaZ"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, X_test, y_train, y_test):\n",
        "\n",
        "  # Import other classifiers as needed\n",
        "\n",
        "  # Train classifiers with different n_components values\n",
        "  model_accuracies={}\n",
        "  svm_rbf=SVC(kernel='rbf')\n",
        "\n",
        "  svm_rbf.fit(X_train, y_train)\n",
        "  y_pred_rbf=svm_rbf.predict(X_test)\n",
        "  accuracy_rbf=calculate_performance(y_test, y_pred_rbf)\n",
        "  model_accuracies['svm_rbf']=accuracy_rbf\n",
        "  \n",
        "  svm_linear = SVC(kernel='linear')\n",
        "  svm_linear.fit(X_train, y_train)\n",
        "  y_pred_linear = svm_linear.predict(X_test)\n",
        "  print(\"pca linear performance: \")\n",
        "  accuracy_linear=calculate_performance(y_test, y_pred_linear)\n",
        "  model_accuracies['svm_linear']=accuracy_linear\n",
        "\n",
        "  svm_poly = SVC(kernel='poly')\n",
        "  svm_poly.fit(X_train, y_train)\n",
        "  y_pred_poly = svm_poly.predict(X_test)\n",
        "  print(\"pca linear performance: \")\n",
        "  accuracy_poly=calculate_performance(y_test, y_pred_poly)\n",
        "  model_accuracies['svm_poly']=accuracy_poly\n",
        "  \n",
        "  rfc = RandomForestClassifier()\n",
        "  rfc.fit(X_train, y_train)\n",
        "  y_pred_rfc = rfc.predict(X_test)\n",
        "  print(\"Random Forest performance: \")\n",
        "  accuracy_rfc=calculate_performance(y_test, y_pred_rfc)\n",
        "  model_accuracies['rfc']=accuracy_rfc\n",
        " \n",
        "  k = 5\n",
        "  knn = KNeighborsClassifier(n_neighbors=k)\n",
        "  knn.fit(X_train, y_train)\n",
        "  y_pred_knn = knn.predict(X_test)\n",
        "  print(\"KNN: \")\n",
        "  accuracy_knn=calculate_performance(y_test, y_pred_knn)\n",
        "  model_accuracies['knn']=accuracy_knn\n",
        "\n",
        "\n",
        "  mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500,activation='relu', solver='adam', random_state=42)\n",
        "  mlp.fit(X_train, y_train)\n",
        "  y_pred = mlp.predict(X_test)\n",
        "  y_pred_mlp = [round(value) for value in y_pred]\n",
        "  print('MLP performance: ')\n",
        "  accuracy_mlp=calculate_performance(y_test, y_pred_mlp)\n",
        "  model_accuracies['mlp']=accuracy_mlp\n",
        "\n",
        "\n",
        "  return model_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4NkfqsJht8ev"
      },
      "outputs": [],
      "source": [
        "def get_data(type,subject_no):\n",
        "    \n",
        "    X,Y=load_EEG(type, subject_no)\n",
        "\n",
        "    kfold=5\n",
        "    skf = StratifiedKFold(n_splits=kfold, random_state=42, shuffle=True)\n",
        "\n",
        "    average_accuracies={}\n",
        "    \n",
        "    for i, (train_index, test_index) in enumerate(skf.split(X, Y)):\n",
        "        train_X=X[train_index]\n",
        "        train_y=Y[train_index]\n",
        "        test_X=X[test_index]\n",
        "        test_y=Y[test_index]\n",
        "        X_train, y_train  = train_augmentation(train_X, train_y)\n",
        "        X_test, y_test = train_augmentation(test_X, test_y)\n",
        "        y_train=y_train.reshape((-1))\n",
        "        y_test=y_test.reshape((-1))\n",
        "        # csp = CSP(n_components=4, reg=0.003, log=False, norm_trace=False)\n",
        "        # csp.fit(X_train, y_train)\n",
        "        # X_train_csp = csp.transform(X_train)\n",
        "        # X_test_csp = csp.transform(X_test)\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        # train_data = scaler.fit_transform(X_train)\n",
        "        # test_data = scaler.transform(X_test)\n",
        "\n",
        "        # n_components =   100\n",
        "\n",
        "        # pca = PCA(n_components=n_components)\n",
        "        # X_train = pca.fit_transform(train_data)\n",
        "        # X_test = pca.transform(test_data)\n",
        "\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "        print(f'fold {i} performance: ')\n",
        "        accuracies=train_model(X_train, X_test, y_train, y_test)\n",
        "        for model_name, accuracy in accuracies.items():\n",
        "            if model_name not in average_accuracies:\n",
        "                average_accuracies[model_name] = []\n",
        "            average_accuracies[model_name].append(accuracy)\n",
        "    for model_name, accuracies in average_accuracies.items():\n",
        "        average_accuracy = np.mean(accuracies)\n",
        "        std_deviation = np.std(accuracies)\n",
        "        print(f\"{model_name} Average Accuracy: {average_accuracy}\")\n",
        "        print(f\"{model_name} Standard Deviation: {std_deviation}\")\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "    return \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yx5cQPnNVpaa"
      },
      "outputs": [],
      "source": [
        "\n",
        "def K_fold_train(X_train, X_test, y_train, y_test):\n",
        "\n",
        "\n",
        "    svm_rbf=SVC(kernel='rbf')\n",
        "\n",
        "    num_folds = 5\n",
        "    kfold = KFold(n_splits=num_folds)\n",
        "    scores_rbf = cross_val_score(svm_rbf, X_train, y_train, cv=kfold)\n",
        "    for fold_idx, accuracy in enumerate(scores_rbf):\n",
        "        print(f\"Fold {fold_idx+1} Accuracy: {accuracy}\")\n",
        "    mean_accuracy_rbf = scores_rbf.mean()\n",
        "    std_deviation_rbf = scores_rbf.std()\n",
        "    print(f'mean_accuracy_rbf: {mean_accuracy_rbf}, std_deviation_rbf: {std_deviation_rbf}')\n",
        "    \n",
        "    svm_linear = SVC(kernel='linear')\n",
        "    scores_linear = cross_val_score(svm_linear, X_train, y_train, cv=kfold)\n",
        "    for fold_idx, accuracy in enumerate(scores_linear):\n",
        "        print(f\"Fold {fold_idx+1} Accuracy: {accuracy}\")\n",
        "    mean_accuracy_linear = scores_linear.mean()\n",
        "    std_deviation_linear = scores_linear.std()\n",
        "    print(f'mean_accuracy_rbf: {mean_accuracy_linear}, std_deviation_rbf: {std_deviation_linear}')\n",
        "\n",
        "\n",
        "    \n",
        "    rfc = RandomForestClassifier()\n",
        "    scores_rfc = cross_val_score(rfc, X_train, y_train, cv=kfold)\n",
        "    for fold_idx, accuracy in enumerate(scores_rfc):\n",
        "        print(f\"Fold {fold_idx+1} Accuracy: {accuracy}\")\n",
        "    mean_accuracy_rfc = scores_rfc.mean()\n",
        "    std_deviation_rfc = scores_rfc.std()\n",
        "    print(f'mean_accuracy_rbf: {mean_accuracy_rfc}, std_deviation_rbf: {std_deviation_rfc}')\n",
        "\n",
        "    \n",
        "    k = 5  \n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    scores_knn = cross_val_score(knn, X_train, y_train, cv=kfold)\n",
        "    for fold_idx, accuracy in enumerate(scores_knn):\n",
        "        print(f\"Fold {fold_idx+1} Accuracy: {accuracy}\")\n",
        "    mean_accuracy_knn = scores_knn.mean()\n",
        "    std_deviation_knn = scores_knn.std()\n",
        "    print(f'mean_accuracy_rbf: {mean_accuracy_knn}, std_deviation_rbf: {std_deviation_knn}')\n",
        "\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500,activation='relu', solver='adam', random_state=42)\n",
        "    scores_mlp = cross_val_score(mlp, X_train, y_train, cv=kfold)\n",
        "    for fold_idx, accuracy in enumerate(scores_mlp):\n",
        "        print(f\"Fold {fold_idx+1} Accuracy: {accuracy}\")\n",
        "    mean_accuracy_mlp = scores_mlp.mean()\n",
        "    std_deviation_mlp = scores_mlp.std()\n",
        "    print(f'mean_accuracy_rbf: {mean_accuracy_mlp}, std_deviation_rbf: {std_deviation_mlp}')\n",
        "\n",
        "\n",
        "\n",
        "    svm_rbf=SVC(kernel='rbf')\n",
        "    \n",
        "\n",
        "\n",
        "    return \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# type=\"Long_words\"\n",
        "# subject_no=6\n",
        "# get_data(type, subject_no)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qWR1Jm-mt8ew"
      },
      "outputs": [],
      "source": [
        "\n",
        "# now = datetime.now()\n",
        "# dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "# with open('EMD_Attempts2.txt', 'a') as file:\n",
        "#     sys.stdout = file\n",
        "#     print(\"time: \", dt_string)\n",
        "    \n",
        "#     type=\"Long_words\"\n",
        "#     subject_no=2\n",
        "#     print(f'{type}, {subject_no}')\n",
        "#     print('features: mean, std, kurtosis, Energy, skewness, Median')\n",
        "#     get_data(type, subject_no)\n",
        "\n",
        "#     sys.stdout = sys.__stdout__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2Iu3g9lt8ex",
        "outputId": "f0566ac8-8122-47a5-83b7-036a90e737d1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# now = datetime.now()\n",
        "# dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "# with open('EMD_Attempts2.txt', 'a') as file:\n",
        "#     sys.stdout = file\n",
        "#     print(\"time: \", dt_string)\n",
        "#     print('**********************************************')\n",
        "#     type=\"Short_Long_words\"\n",
        "#     subject_no=[1,5,8,9,10,14]\n",
        "#     print(f'{type}')\n",
        "#     print('features: mean, std, kurtosis, Energy, skewness, Median')\n",
        "#     for i in range(len(subject_no)):\n",
        "#         print(f'{subject_no[i]}')\n",
        "#         get_data(type, subject_no[i])\n",
        "\n",
        "#     sys.stdout = sys.__stdout__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KTLpPnbut8ex"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "with total_sample: 1152, epoch size: 512 and strides: 192\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/tseringj/final_project/EMD_Attempt2.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShort_Long_words\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m subject_no\u001b[39m=\u001b[39m\u001b[39m14\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m get_data(\u001b[39mtype\u001b[39;49m, subject_no)\n",
            "\u001b[1;32m/home/tseringj/final_project/EMD_Attempt2.ipynb Cell 21\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(type, subject_no)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m test_X\u001b[39m=\u001b[39mX[test_index]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m test_y\u001b[39m=\u001b[39mY[test_index]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m X_train, y_train  \u001b[39m=\u001b[39m train_augmentation(train_X, train_y)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m X_test, y_test \u001b[39m=\u001b[39m train_augmentation(test_X, test_y)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m y_train\u001b[39m=\u001b[39my_train\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
            "\u001b[1;32m/home/tseringj/final_project/EMD_Attempt2.ipynb Cell 21\u001b[0m in \u001b[0;36mtrain_augmentation\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mif\u001b[39;00m j\u001b[39m+\u001b[39mepoch_size \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m total_samples:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m feature\u001b[39m=\u001b[39mfeature_extraction(data)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m feature\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray(feature)\u001b[39m.\u001b[39mreshape((\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# print(feature.shape)\u001b[39;00m\n",
            "\u001b[1;32m/home/tseringj/final_project/EMD_Attempt2.ipynb Cell 21\u001b[0m in \u001b[0;36mfeature_extraction\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(row):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     emd \u001b[39m=\u001b[39m EMD()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     IMFs \u001b[39m=\u001b[39m emd(data[i,:], max_imf\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     feature_imfs\u001b[39m=\u001b[39m[]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.192.12.66/home/tseringj/final_project/EMD_Attempt2.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     feature_imfs\u001b[39m=\u001b[39mcompute_time_domain_features(IMFs[\u001b[39m2\u001b[39m,:])\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/PyEMD/EMD.py:120\u001b[0m, in \u001b[0;36mEMD.__call__\u001b[0;34m(self, S, T, max_imf)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, S: np\u001b[39m.\u001b[39mndarray, T: Optional[np\u001b[39m.\u001b[39mndarray] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, max_imf: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m--> 120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49memd(S, T\u001b[39m=\u001b[39;49mT, max_imf\u001b[39m=\u001b[39;49mmax_imf)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/PyEMD/EMD.py:853\u001b[0m, in \u001b[0;36mEMD.emd\u001b[0;34m(self, S, T, max_imf)\u001b[0m\n\u001b[1;32m    849\u001b[0m nzm \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(indzer)\n\u001b[1;32m    851\u001b[0m \u001b[39mif\u001b[39;00m extNo \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 853\u001b[0m     max_env, min_env, eMax, eMin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_max_min_spline(T, imf)\n\u001b[1;32m    854\u001b[0m     mean[:] \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m (max_env \u001b[39m+\u001b[39m min_env)\n\u001b[1;32m    856\u001b[0m     imf_old \u001b[39m=\u001b[39m imf\u001b[39m.\u001b[39mcopy()\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/PyEMD/EMD.py:160\u001b[0m, in \u001b[0;36mEMD.extract_max_min_spline\u001b[0;34m(self, T, S)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39m#########################################\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39m# Extrapolation of signal (over boundaries)\u001b[39;00m\n\u001b[1;32m    158\u001b[0m max_extrema, min_extrema \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_points(T, S, max_pos, max_val, min_pos, min_val)\n\u001b[0;32m--> 160\u001b[0m _, max_spline \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mspline_points(T, max_extrema)\n\u001b[1;32m    161\u001b[0m _, min_spline \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspline_points(T, min_extrema)\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m max_spline, min_spline, max_extrema, min_extrema\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/PyEMD/EMD.py:484\u001b[0m, in \u001b[0;36mEMD.spline_points\u001b[0;34m(self, T, extrema)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39melif\u001b[39;00m kind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcubic\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    483\u001b[0m     \u001b[39mif\u001b[39;00m extrema\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m--> 484\u001b[0m         \u001b[39mreturn\u001b[39;00m t, interp1d(extrema[\u001b[39m0\u001b[39;49m], extrema[\u001b[39m1\u001b[39;49m], kind\u001b[39m=\u001b[39;49mkind)(t)\n\u001b[1;32m    485\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    486\u001b[0m         \u001b[39mreturn\u001b[39;00m cubic_spline_3pts(extrema[\u001b[39m0\u001b[39m], extrema[\u001b[39m1\u001b[39m], t)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/interpolate/_interpolate.py:564\u001b[0m, in \u001b[0;36minterp1d.__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    561\u001b[0m         yy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones_like(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y)\n\u001b[1;32m    562\u001b[0m         rewrite_nan \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 564\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spline \u001b[39m=\u001b[39m make_interp_spline(xx, yy, k\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m    565\u001b[0m                                   check_finite\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    566\u001b[0m \u001b[39mif\u001b[39;00m rewrite_nan:\n\u001b[1;32m    567\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m_call_nan_spline\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/interpolate/_bsplines.py:1286\u001b[0m, in \u001b[0;36mmake_interp_spline\u001b[0;34m(x, y, k, t, bc_type, axis, check_finite)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         t \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mr_[(x[\u001b[39m0\u001b[39m],)\u001b[39m*\u001b[39m(k\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m   1283\u001b[0m                    t[\u001b[39m1\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],\n\u001b[1;32m   1284\u001b[0m                    (x[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m],)\u001b[39m*\u001b[39m(k\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)]\n\u001b[1;32m   1285\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1286\u001b[0m         t \u001b[39m=\u001b[39m _not_a_knot(x, k)\n\u001b[1;32m   1287\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1288\u001b[0m     t \u001b[39m=\u001b[39m _augknt(x, k)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/interpolate/_bsplines.py:806\u001b[0m, in \u001b[0;36m_not_a_knot\u001b[0;34m(x, k)\u001b[0m\n\u001b[1;32m    804\u001b[0m m \u001b[39m=\u001b[39m (k \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    805\u001b[0m t \u001b[39m=\u001b[39m x[m\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m:\u001b[39m-\u001b[39mm\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m--> 806\u001b[0m t \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mr_[(x[\u001b[39m0\u001b[39;49m],)\u001b[39m*\u001b[39;49m(k\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m), t, (x[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],)\u001b[39m*\u001b[39;49m(k\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)]\n\u001b[1;32m    807\u001b[0m \u001b[39mreturn\u001b[39;00m t\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/index_tricks.py:408\u001b[0m, in \u001b[0;36mAxisConcatenator.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    405\u001b[0m         arraytypes\u001b[39m.\u001b[39mappend(newobj\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    407\u001b[0m \u001b[39m# Ensure that scalars won't up-cast unless warranted\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m final_dtype \u001b[39m=\u001b[39m find_common_type(arraytypes, scalartypes)\n\u001b[1;32m    409\u001b[0m \u001b[39mif\u001b[39;00m final_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m scalars:\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/numerictypes.py:654\u001b[0m, in \u001b[0;36mfind_common_type\u001b[0;34m(array_types, scalar_types)\u001b[0m\n\u001b[1;32m    651\u001b[0m array_types \u001b[39m=\u001b[39m [dtype(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m array_types]\n\u001b[1;32m    652\u001b[0m scalar_types \u001b[39m=\u001b[39m [dtype(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m scalar_types]\n\u001b[0;32m--> 654\u001b[0m maxa \u001b[39m=\u001b[39m _can_coerce_all(array_types)\n\u001b[1;32m    655\u001b[0m maxsc \u001b[39m=\u001b[39m _can_coerce_all(scalar_types)\n\u001b[1;32m    657\u001b[0m \u001b[39mif\u001b[39;00m maxa \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/numerictypes.py:584\u001b[0m, in \u001b[0;36m_can_coerce_all\u001b[0;34m(dtypelist, start)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[39mwhile\u001b[39;00m thisind \u001b[39m<\u001b[39m __len_test_types:\n\u001b[1;32m    583\u001b[0m     newdtype \u001b[39m=\u001b[39m dtype(__test_types[thisind])\n\u001b[0;32m--> 584\u001b[0m     numcoerce \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m([x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m dtypelist \u001b[39mif\u001b[39;00m newdtype \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m x])\n\u001b[1;32m    585\u001b[0m     \u001b[39mif\u001b[39;00m numcoerce \u001b[39m==\u001b[39m N:\n\u001b[1;32m    586\u001b[0m         \u001b[39mreturn\u001b[39;00m newdtype\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/numerictypes.py:584\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[39mwhile\u001b[39;00m thisind \u001b[39m<\u001b[39m __len_test_types:\n\u001b[1;32m    583\u001b[0m     newdtype \u001b[39m=\u001b[39m dtype(__test_types[thisind])\n\u001b[0;32m--> 584\u001b[0m     numcoerce \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m([x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m dtypelist \u001b[39mif\u001b[39;00m newdtype \u001b[39m>\u001b[39;49m\u001b[39m=\u001b[39;49m x])\n\u001b[1;32m    585\u001b[0m     \u001b[39mif\u001b[39;00m numcoerce \u001b[39m==\u001b[39m N:\n\u001b[1;32m    586\u001b[0m         \u001b[39mreturn\u001b[39;00m newdtype\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "type=\"Short_Long_words\"\n",
        "subject_no=14\n",
        "get_data(type, subject_no)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
