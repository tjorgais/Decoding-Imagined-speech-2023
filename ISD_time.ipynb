{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = {\"Long_words\": \"/home/tseringj/final_project/Long_Words\",\n",
    "               \"Short_Long_words\": \"/home/tseringj/final_project/Short_Long_words\",\n",
    "               \"Short_words\": \"/home/tseringj/final_project/Short_words\",\n",
    "               \"Vowels\": \"/home/tseringj/final_project/Vowels\"}\n",
    "\n",
    "words_dict = {\n",
    "    \"Long_words\": [\"cooperate\", \"independent\"],\n",
    "    \"Short_Long_words\": [\"cooperate\", \"in\"],\n",
    "    \"Short_words\": [\"out\", \"in\", \"up\"],\n",
    "    \"Vowels\": [\"a\", \"i\", \"u\"]\n",
    "}\n",
    "\n",
    "numeric_labels = {\n",
    "    \"Long_words\": {\"cooperate\": 0, \"independent\": 1},\n",
    "    \"Short_Long_words\": {\"cooperate\": 0, \"in\": 1},\n",
    "    \"Short_words\": {\"out\": 0, \"in\": 1, \"up\": 2},\n",
    "    \"Vowels\": {\"a\": 0, \"i\": 1, \"u\": 2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matrix_to_load = \"eeg_data_wrt_task_rep_no_eog_256Hz_last_beep\"\n",
    "\n",
    "def load_EEG(type, subject_no):\n",
    "    path = folder_path[type]\n",
    "    words = words_dict[type]\n",
    "    for subject_file in os.scandir(path):\n",
    "        if not (subject_file.is_file() and subject_file.name.endswith('.mat') and\n",
    "                int(re.search(\"[0-9]+\", subject_file.name).group(0)) == subject_no):\n",
    "            continue\n",
    "        mat = sio.loadmat(subject_file.path)[matrix_to_load]\n",
    "        \n",
    "        temp = f\"{path}/temp_files3\"\n",
    "        if not os.path.exists(temp):\n",
    "            os.mkdir(temp)\n",
    "        temp = f\"{temp}/{subject_no}\"\n",
    "\n",
    "        if not os.path.exists(temp):\n",
    "            os.mkdir(temp)\n",
    "        X = []\n",
    "        Y = []\n",
    "        for index, eeg in np.ndenumerate(mat):\n",
    "            temp2 = f\"{temp}/{words[index[0]]}_{index[1] + 1}.npy\" #storing each trial\n",
    "            X.append(temp2)\n",
    "            Y.append(words[index[0]])\n",
    "            if not os.path.exists(temp2):\n",
    "                np.save(temp2, eeg)\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_time_domain_features(eeg_data):\n",
    "    time_features = {}\n",
    "\n",
    "    # Mean\n",
    "    time_features['mean'] = np.mean(eeg_data)\n",
    "\n",
    "    # Standard deviation\n",
    "    time_features['std'] = np.std(eeg_data)\n",
    "    \n",
    "    # Kurtosis\n",
    "    time_features['kurtosis'] = kurtosis(eeg_data)\n",
    "    '''\n",
    "\n",
    "    # Energy\n",
    "    time_features['Energy'] = np.sum(np.square(eeg_data))\n",
    "\n",
    "    # RMS (Root Mean Square)\n",
    "    time_features['RMS'] = np.sqrt(np.mean(np.square(eeg_data)))\n",
    "\n",
    "    # Zero-crossing rate\n",
    "    zero_crossings = np.where(np.diff(np.sign(eeg_data)))[0]\n",
    "    zero_crossing_rate = len(zero_crossings) / (len(eeg_data) - 1)\n",
    "    time_features['Zero-crossing rate'] = zero_crossing_rate\n",
    "\n",
    "    # Hjorth parameters\n",
    "    # Hjorth parameters\n",
    "    time_features['hjorth_activity'] = np.sqrt(time_features['Energy'] / time_features['std']**2)\n",
    "    time_features['hjorth_mobility'] = time_features['mean'] / time_features['std']\n",
    "    time_features['hjorth_complexity'] = time_features['kurtosis'] / (time_features['std']**4)\n",
    "\n",
    "    # Skewness\n",
    "    time_features['Skewness'] = skew(eeg_data)\n",
    "\n",
    "    # Median\n",
    "    time_features['Median'] = np.median(eeg_data)\n",
    "\n",
    "\n",
    "    # Range\n",
    "    time_features['Range'] = np.ptp(eeg_data)\n",
    "\n",
    "    # Inter-quartile range\n",
    "    time_features['Inter-quartile range'] = np.percentile(eeg_data, 75) - np.percentile(eeg_data, 25)\n",
    "\n",
    "    # Variance\n",
    "    time_features['Variance'] = np.var(eeg_data)\n",
    "    '''\n",
    "\n",
    "    # # Autocorrelation\n",
    "    # autocorr = np.correlate(eeg_data, eeg_data, mode='full')\n",
    "    # time_features['Autocorrelation'] = autocorr[len(autocorr)//2:]\n",
    "\n",
    "\n",
    "    return time_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(eeg_data):\n",
    "  channels_to_select = [i for i in range(64) if i not in [0, 9, 32, 63]]  # Channels to select (excluding 0, 9, 32, and 63)\n",
    "  data=eeg_data[channels_to_select,:]\n",
    "  features=[]\n",
    "\n",
    "  for i in range(60):\n",
    "    results=compute_time_domain_features(data[i,:])\n",
    "    features.extend(list(results.values()))\n",
    "\n",
    "    \n",
    "  return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasub2 = sio.loadmat('Long_Words/sub_2b_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub3 = sio.loadmat('Long_Words/sub_3b_ch80_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub6 = sio.loadmat('Long_Words/sub_6_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub7 = sio.loadmat('Long_Words/sub_7_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub9 = sio.loadmat('Long_Words/sub_9c_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']\n",
    "datasub2 = sio.loadmat('Long_Words/sub_11b_ch64_l_eog_removed_256Hz.mat')['eeg_data_wrt_task_rep_no_eog_256Hz_last_beep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature=extract_features(datasub2[0][0])\n",
    "len(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for data augmentation\n",
    "\n",
    "def train_augmentation(X,Y):\n",
    "    final_data= np.empty((0,181))\n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        with open(X[i], 'rb') as f:\n",
    "            data = np.load(f)\n",
    "\n",
    "            result=np.empty((0,180))\n",
    "        \n",
    "            \n",
    "            # Loop through the data with a stride of 64 samples\n",
    "            for j in range(0, 1280, 64):\n",
    "            # Select a window of 256 samples from the data, starting at index i\n",
    "                window = data[:, j:j+256]\n",
    "                features=extract_features(window)\n",
    "                \n",
    "                result=np.vstack((result, (np.array(features)).reshape((1,-1))))\n",
    "                \n",
    "\n",
    "                # Stop the loop if i+256 is greater than or equal to 1280\n",
    "                if j+256 >= 1280:\n",
    "                    break\n",
    "            if numeric_labels[type][Y[i]]==0:\n",
    "              label=np.zeros((17,1))\n",
    "              result=np.hstack((result, label))\n",
    "            else:\n",
    "              label=np.ones((17,1))\n",
    "              result=np.hstack((result, label))\n",
    "            \n",
    "            final_data=np.vstack((final_data, result))\n",
    "            \n",
    "    \n",
    "    \n",
    "        \n",
    "    return final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef test_augmentation(X,Y):\\n    final_data= np.empty((0,121))\\n    for i in range(len(X)):\\n        \\n        with open(X[i], 'rb') as f:\\n            data = np.load(f)\\n\\n            result=np.empty((0,120))\\n        \\n            \\n            # Loop through the data with a stride of 64 samples\\n            for j in range(0, 1280, 360):\\n            # Select a window of 256 samples from the data, starting at index i\\n                window = data[:, j:j+360]\\n                features=extract_features(window)\\n                \\n                result=np.vstack((result, (np.array(features)).reshape((1,-1))))\\n                \\n                \\n\\n                # Stop the loop if i+256 is greater than or equal to 1280\\n                if j+360 >= 1280:\\n                    break\\n            if numeric_labels[type][Y[i]]==0:\\n              label=np.zeros((4,1))\\n              result=np.hstack((result, label))\\n            else:\\n              label=np.ones((4,1))\\n              result=np.hstack((result, label))\\n            final_data=np.vstack((final_data, result))\\n            \\n    \\n    \\n        \\n    return final_data\\n\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function for data augmentation\n",
    "'''\n",
    "def test_augmentation(X,Y):\n",
    "    final_data= np.empty((0,121))\n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        with open(X[i], 'rb') as f:\n",
    "            data = np.load(f)\n",
    "\n",
    "            result=np.empty((0,120))\n",
    "        \n",
    "            \n",
    "            # Loop through the data with a stride of 64 samples\n",
    "            for j in range(0, 1280, 360):\n",
    "            # Select a window of 256 samples from the data, starting at index i\n",
    "                window = data[:, j:j+360]\n",
    "                features=extract_features(window)\n",
    "                \n",
    "                result=np.vstack((result, (np.array(features)).reshape((1,-1))))\n",
    "                \n",
    "                \n",
    "\n",
    "                # Stop the loop if i+256 is greater than or equal to 1280\n",
    "                if j+360 >= 1280:\n",
    "                    break\n",
    "            if numeric_labels[type][Y[i]]==0:\n",
    "              label=np.zeros((4,1))\n",
    "              result=np.hstack((result, label))\n",
    "            else:\n",
    "              label=np.ones((4,1))\n",
    "              result=np.hstack((result, label))\n",
    "            final_data=np.vstack((final_data, result))\n",
    "            \n",
    "    \n",
    "    \n",
    "        \n",
    "    return final_data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for data augmentation\n",
    "\n",
    "def test_augmentation(X,Y):\n",
    "    final_data= np.empty((0,181))\n",
    "    for i in range(len(X)):\n",
    "        \n",
    "        with open(X[i], 'rb') as f:\n",
    "            data = np.load(f)\n",
    "        \n",
    "            features=extract_features(data)\n",
    "                \n",
    "            features=np.array(features).reshape((1,-1))\n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "            if numeric_labels[type][Y[i]]==0:\n",
    "              label=np.zeros((1,1))\n",
    "              features=np.hstack((features, label))\n",
    "            else:\n",
    "              label=np.ones((1,1))\n",
    "              features=np.hstack((features, label))\n",
    "            final_data=np.vstack((final_data, features))\n",
    "            \n",
    "    \n",
    "    \n",
    "        \n",
    "    return final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f'accuracy: {accuracy}, precision: {precision}, recall: {recall}, f1 {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(type,subject_no):\n",
    "    X,Y=load_EEG(type, subject_no)\n",
    "        \n",
    "    # Example usage\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, Y, test_size=0.2, stratify= Y,random_state=42)\n",
    "    train_data = train_augmentation(train_X, train_y)\n",
    "    test_data = test_augmentation(test_X, test_y)\n",
    "    X_train, y_train=train_data[:,:-1], train_data[:,-1]\n",
    "    X_test, y_test=test_data[:,:-1], test_data[:,-1]\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, X_test, y_train, y_test):\n",
    "  scaler = StandardScaler()\n",
    "  train_data = scaler.fit_transform(X_train)\n",
    "  test_data = scaler.transform(X_test)\n",
    "  # train_data=X_train\n",
    "  # test_data=X_test\n",
    "  n_components =   100# Specify the number of components you want to keep\n",
    "\n",
    "  pca = PCA(n_components=n_components)\n",
    "  train_pca = pca.fit_transform(train_data)\n",
    "  test_pca = pca.transform(test_data)\n",
    "  print(train_pca.shape, test_pca.shape)\n",
    "  \n",
    "  y_train=y_train.astype(int)\n",
    "  y_test=y_test.astype(int)\n",
    "  print(sum(y_train), sum(y_test))\n",
    "  # Import other classifiers as needed\n",
    "\n",
    "  # Train classifiers with different n_components values\n",
    "  model=SVC(kernel='rbf')\n",
    "  model.fit(train_pca, y_train)\n",
    "  y_pred=model.predict(test_pca)\n",
    "  calculate_performance(y_test, y_pred)\n",
    "  \n",
    "  clf1 = SVC(kernel='linear')\n",
    "  clf1.fit(train_pca, y_train)\n",
    "  y_pred_pca = clf1.predict(test_pca)\n",
    "  print(\"pca linear performance: \")\n",
    "  calculate_performance(y_test, y_pred_pca)\n",
    "\n",
    "\n",
    "  \n",
    "  clf2 = RandomForestClassifier()\n",
    "  clf2.fit(train_pca, y_train)\n",
    "  y_pred_rfc = clf2.predict(test_pca)\n",
    "  print(\"Random Forest performance: \")\n",
    "  calculate_performance(y_test, y_pred_rfc)\n",
    "\n",
    "  model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500,activation='relu', solver='adam', random_state=42)\n",
    "  model.fit(train_pca, y_train)\n",
    "  y_pred = model.predict(test_pca)\n",
    "  y_pred_mlp = [round(value) for value in y_pred]\n",
    "  print('MLP performance: ')\n",
    "  calculate_performance(y_test, y_pred_mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "type=\"Long_words\"\n",
    "subject_no=2\n",
    "X_train, X_test, y_train, y_test=get_data(type, subject_no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2720, 100) (40, 100)\n",
      "1360 20\n",
      "accuracy: 0.55, precision: 0.5714285714285714, recall: 0.4, f1 0.47058823529411764\n",
      "pca linear performance: \n",
      "accuracy: 0.5, precision: 0.5, recall: 0.3, f1 0.37499999999999994\n",
      "Random Forest performance: \n",
      "accuracy: 0.525, precision: 0.5384615384615384, recall: 0.35, f1 0.4242424242424242\n",
      "MLP performance: \n",
      "accuracy: 0.575, precision: 0.5652173913043478, recall: 0.65, f1 0.6046511627906976\n"
     ]
    }
   ],
   "source": [
    "train_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2720, 50) (40, 50)\n",
    "1360 20\n",
    "accuracy: 0.55, precision: 0.5625, recall: 0.45, f1 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
